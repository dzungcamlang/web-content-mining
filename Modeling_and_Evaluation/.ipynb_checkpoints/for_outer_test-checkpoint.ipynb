{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Oct 15 13:59:06 2016\n",
    "\n",
    "@author: Office\n",
    "\"\"\"\n",
    "import os, csv\n",
    "import numpy as np\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.utils import shuffle\n",
    "from data_manipulation_library import *\n",
    "from learning_model_modules import *\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "global labeled_dataset\n",
    "labeled_dataset = []\n",
    "number_of_file = 0\n",
    "\n",
    "### Parameter Setting\n",
    "length_features = 95 # normal index\n",
    "end_point_for_feature_scaling = 87 # array index \n",
    "num_of_test_sample = 3\n",
    "\n",
    "sample_percent = 0.1\n",
    "sample_token = 1\n",
    "times = 10\n",
    "\n",
    "full_path = 'C:\\\\Users\\\\Office\\\\Documents\\\\Python Workspace\\\\Tag Classification Project\\\\'\n",
    "dataset_path = full_path+'Dataset\\\\data_labeled'\n",
    "#data_path = full_path+'Dataset\\\\data_labeled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def string_to_float(li):\n",
    "    for i, j in enumerate(li):\n",
    "        li[i] = float(j)\n",
    "    return li\n",
    "\n",
    "def mean_std_print(l1, l2, l3, l4, k1, k2, k3, k4, m1, m2, m3, m4, n1, n2, n3, n4):\n",
    "    \n",
    "    l1 = string_to_float(l1)\n",
    "    l2 = string_to_float(l2)\n",
    "    l3 = string_to_float(l3)\n",
    "    l4 = string_to_float(l4)\n",
    "    \n",
    "    k1 = string_to_float(k1)\n",
    "    k2 = string_to_float(k2)\n",
    "    k3 = string_to_float(k3)\n",
    "    k4 = string_to_float(k4)\n",
    "    \n",
    "    m1 = string_to_float(m1)\n",
    "    m2 = string_to_float(m2)\n",
    "    m3 = string_to_float(m3)\n",
    "    m4 = string_to_float(m4)\n",
    "    \n",
    "    n1 = string_to_float(n1)\n",
    "    n2 = string_to_float(n2)\n",
    "    n3 = string_to_float(n3)\n",
    "    n4 = string_to_float(n4)\n",
    "    \n",
    "    print 'class 0:', np.mean(l1)*100, np.std(l1)*100, '-', np.mean(l2)*100, np.std(l2)*100, '-', np.mean(l3)*100,np.std(l3)*100, '-', np.mean(l4)*100,np.std(l4)*100\n",
    "    print 'class 1:', np.mean(k1)*100, np.std(k1)*100, '-', np.mean(k2)*100, np.std(k2)*100, '-', np.mean(k3)*100,np.std(k3)*100, '-', np.mean(k4)*100,np.std(k4)*100\n",
    "    print 'class 2:', np.mean(m1)*100, np.std(m1)*100, '-', np.mean(m2)*100, np.std(m2)*100, '-', np.mean(l3)*100,np.std(m3)*100, '-', np.mean(m4)*100,np.std(m4)*100\n",
    "    print 'class 3:', np.mean(n1)*100, np.std(n1)*100, '-', np.mean(n2)*100, np.std(n2)*100, '-', np.mean(l3)*100,np.std(n3)*100, '-', np.mean(n4)*100,np.std(n4)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Aljazeera\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Boston\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CNN\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CSmonitor\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\EuroNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\FoxNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Reuters\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Telegraph\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\TheGlobeandmail\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\USAToday\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\WSJ\n",
      "0\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCAU\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCAU\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Aljazeera\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Boston\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CNN\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CSmonitor\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\EuroNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\FoxNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Reuters\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Telegraph\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\TheGlobeandmail\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\USAToday\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\WSJ\n",
      "0\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCNews\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCAU\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Boston\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CNN\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CSmonitor\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\EuroNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\FoxNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Reuters\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Telegraph\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\TheGlobeandmail\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\USAToday\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\WSJ\n",
      "0\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Aljazeera\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCAU\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Aljazeera\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CNN\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CSmonitor\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\EuroNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\FoxNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Reuters\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Telegraph\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\TheGlobeandmail\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\USAToday\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\WSJ\n",
      "0\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Boston\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCAU\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Aljazeera\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Boston\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CSmonitor\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\EuroNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\FoxNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Reuters\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Telegraph\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\TheGlobeandmail\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\USAToday\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\WSJ\n",
      "0\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CNN\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCAU\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Aljazeera\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Boston\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CNN\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\EuroNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\FoxNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Reuters\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Telegraph\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\TheGlobeandmail\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\USAToday\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\WSJ\n",
      "0\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CSmonitor\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCAU\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Aljazeera\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Boston\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CNN\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CSmonitor\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\FoxNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Reuters\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Telegraph\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\TheGlobeandmail\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\USAToday\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\WSJ\n",
      "0\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\EuroNews\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCAU\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Aljazeera\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Boston\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CNN\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CSmonitor\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\EuroNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Reuters\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Telegraph\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\TheGlobeandmail\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\USAToday\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\WSJ\n",
      "0\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\FoxNews\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCAU\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Aljazeera\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Boston\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CNN\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CSmonitor\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\EuroNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\FoxNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Telegraph\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\TheGlobeandmail\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\USAToday\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\WSJ\n",
      "0\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Reuters\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCAU\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Aljazeera\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Boston\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CNN\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CSmonitor\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\EuroNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\FoxNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Reuters\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\TheGlobeandmail\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\USAToday\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\WSJ\n",
      "0\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Telegraph\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCAU\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Aljazeera\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Boston\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CNN\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CSmonitor\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\EuroNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\FoxNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Reuters\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Telegraph\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\USAToday\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\WSJ\n",
      "0\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\TheGlobeandmail\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCAU\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Aljazeera\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Boston\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CNN\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CSmonitor\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\EuroNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\FoxNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Reuters\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Telegraph\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\TheGlobeandmail\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\WSJ\n",
      "0\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\USAToday\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCAU\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\ABCNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Aljazeera\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Boston\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CNN\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\CSmonitor\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\EuroNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\FoxNews\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Reuters\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\Telegraph\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\TheGlobeandmail\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\USAToday\n",
      "0\n",
      "Found directory: C:\\Users\\Office\\Documents\\Python Workspace\\Tag Classification Project\\Dataset\\data_labeled\\WSJ\n"
     ]
    }
   ],
   "source": [
    "c0p_list = []\n",
    "c0r_list = []\n",
    "c0f_list = []\n",
    "c0s_list = []\n",
    "\n",
    "c1p_list = []\n",
    "c1r_list = []\n",
    "c1f_list = []\n",
    "c1s_list = []\n",
    "\n",
    "c2p_list = []\n",
    "c2r_list = []\n",
    "c2f_list = []\n",
    "c2s_list = []\n",
    "\n",
    "c3p_list = []\n",
    "c3r_list = []\n",
    "c3f_list = []\n",
    "c3s_list = []\n",
    "\n",
    "p_micro_list = []\n",
    "r_micro_list = []\n",
    "f_micro_list = []\n",
    "\n",
    "p_macro_list = []\n",
    "r_macro_list = []\n",
    "f_macro_list = []\n",
    "\n",
    "\n",
    "# SET 1\n",
    "# random_list = [1,0,0,0,0,0,0,1,0,0,0,1,0]\n",
    "# train1 = new_load_dataset(dataset_path, random_list, 1)\n",
    "# test1 = new_load_dataset(dataset_path, random_list, 0)\n",
    "# print \"\\n\\n\"\n",
    "# random_list = [0,0,0,0,1,0,0,0,0,0,0,0,1]\n",
    "# train2 = new_load_dataset(dataset_path, random_list, 1)\n",
    "# test2 = new_load_dataset(dataset_path, random_list, 0)\n",
    "# print \"\\n\\n\"\n",
    "# random_list = [0,0,0,1,0,0,0,0,1,0,0,0,0]\n",
    "# train3 = new_load_dataset(dataset_path, random_list, 1)\n",
    "# test3 = new_load_dataset(dataset_path, random_list, 0)\n",
    "# print \"\\n\\n\"\n",
    "# random_list = [0,1,0,0,0,1,0,0,0,0,1,0,0]\n",
    "# train4 = new_load_dataset(dataset_path, random_list, 1)\n",
    "# test4 = new_load_dataset(dataset_path, random_list, 0)\n",
    "# print \"\\n\\n\"\n",
    "# random_list = [0,0,1,0,0,0,1,0,0,1,0,0,0]\n",
    "# train5 = new_load_dataset(dataset_path, random_list, 1)\n",
    "# test5 = new_load_dataset(dataset_path, random_list, 0)\n",
    "\n",
    "############################\n",
    "# SET 2\n",
    "# random_list = [0,0,0,0,0,0,0,1,1,0,0,1,0]\n",
    "# train1 = new_load_dataset(dataset_path, random_list, 1)\n",
    "# test1 = new_load_dataset(dataset_path, random_list, 0)\n",
    "# print \"\\n\\n\"\n",
    "# random_list = [1,0,0,0,0,0,0,0,0,0,0,0,1]\n",
    "# train2 = new_load_dataset(dataset_path, random_list, 1)\n",
    "# test2 = new_load_dataset(dataset_path, random_list, 0)\n",
    "# print \"\\n\\n\"\n",
    "# random_list = [0,1,0,1,1,0,0,0,0,0,0,0,0]\n",
    "# train3 = new_load_dataset(dataset_path, random_list, 1)\n",
    "# test3 = new_load_dataset(dataset_path, random_list, 0)\n",
    "# print \"\\n\\n\"\n",
    "# random_list = [0,0,0,0,0,1,0,0,0,0,1,0,0]\n",
    "# train4 = new_load_dataset(dataset_path, random_list, 1)\n",
    "# test4 = new_load_dataset(dataset_path, random_list, 0)\n",
    "# print \"\\n\\n\"\n",
    "# random_list = [0,0,1,0,0,0,1,0,0,1,0,0,0]\n",
    "# train5 = new_load_dataset(dataset_path, random_list, 1)\n",
    "# test5 = new_load_dataset(dataset_path, random_list, 0)\n",
    "\n",
    "\n",
    "\n",
    "######################################\n",
    "\n",
    "random_list = [1,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "train1 = new_load_dataset(dataset_path, random_list, 1)\n",
    "test1 = new_load_dataset(dataset_path, random_list, 0)\n",
    "print \"\\n\\n\"\n",
    "random_list = [0,1,0,0,0,0,0,0,0,0,0,0,0]\n",
    "train2 = new_load_dataset(dataset_path, random_list, 1)\n",
    "test2 = new_load_dataset(dataset_path, random_list, 0)\n",
    "print \"\\n\\n\"\n",
    "random_list = [0,0,1,0,0,0,0,0,0,0,0,0,0]\n",
    "train3 = new_load_dataset(dataset_path, random_list, 1)\n",
    "test3 = new_load_dataset(dataset_path, random_list, 0)\n",
    "print \"\\n\\n\"\n",
    "random_list = [0,0,0,1,0,0,0,0,0,0,0,0,0]\n",
    "train4 = new_load_dataset(dataset_path, random_list, 1)\n",
    "test4 = new_load_dataset(dataset_path, random_list, 0)\n",
    "print \"\\n\\n\"\n",
    "random_list = [0,0,0,0,1,0,0,0,0,0,0,0,0]\n",
    "train5 = new_load_dataset(dataset_path, random_list, 1)\n",
    "test5 = new_load_dataset(dataset_path, random_list, 0)\n",
    "print \"\\n\\n\"\n",
    "random_list = [0,0,0,0,0,1,0,0,0,0,0,0,0]\n",
    "train6 = new_load_dataset(dataset_path, random_list, 1)\n",
    "test6 = new_load_dataset(dataset_path, random_list, 0)\n",
    "print \"\\n\\n\"\n",
    "random_list = [0,0,0,0,0,0,1,0,0,0,0,0,0]\n",
    "train7 = new_load_dataset(dataset_path, random_list, 1)\n",
    "test7 = new_load_dataset(dataset_path, random_list, 0)\n",
    "print \"\\n\\n\"\n",
    "random_list = [0,0,0,0,0,0,0,1,0,0,0,0,0]\n",
    "train8 = new_load_dataset(dataset_path, random_list, 1)\n",
    "test8 = new_load_dataset(dataset_path, random_list, 0)\n",
    "print \"\\n\\n\"\n",
    "random_list = [0,0,0,0,0,0,0,0,1,0,0,0,0]\n",
    "train9 = new_load_dataset(dataset_path, random_list, 1)\n",
    "test9 = new_load_dataset(dataset_path, random_list, 0)\n",
    "print \"\\n\\n\"\n",
    "random_list = [0,0,0,0,0,0,0,0,0,1,0,0,0]\n",
    "train10 = new_load_dataset(dataset_path, random_list, 1)\n",
    "test10 = new_load_dataset(dataset_path, random_list, 0)\n",
    "print \"\\n\\n\"\n",
    "random_list = [0,0,0,0,0,0,0,0,0,0,1,0,0]\n",
    "train11 = new_load_dataset(dataset_path, random_list, 1)\n",
    "test11 = new_load_dataset(dataset_path, random_list, 0)\n",
    "print \"\\n\\n\"\n",
    "random_list = [0,0,0,0,0,0,0,0,0,0,0,1,0]\n",
    "train12 = new_load_dataset(dataset_path, random_list, 1)\n",
    "test12 = new_load_dataset(dataset_path, random_list, 0)\n",
    "print \"\\n\\n\"\n",
    "random_list = [0,0,0,0,0,0,0,0,0,0,0,0,1]\n",
    "train13 = new_load_dataset(dataset_path, random_list, 1)\n",
    "test13 = new_load_dataset(dataset_path, random_list, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      1.00      1.00       145\n",
      "    class 1       1.00      1.00      1.00       274\n",
      "    class 2       1.00      1.00      1.00      2913\n",
      "    class 3       0.99      1.00      1.00      1948\n",
      "\n",
      "avg / total       1.00      1.00      1.00      5280\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.86      1.00      0.93       147\n",
      "    class 1       1.00      1.00      1.00       171\n",
      "    class 2       0.87      1.00      0.93      2117\n",
      "    class 3       1.00      0.70      0.82      1084\n",
      "\n",
      "avg / total       0.92      0.91      0.90      3519\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.82      1.00      0.90       174\n",
      "    class 1       1.00      0.87      0.93       183\n",
      "    class 2       0.82      0.49      0.62      2111\n",
      "    class 3       0.63      0.88      0.74      2143\n",
      "\n",
      "avg / total       0.74      0.71      0.70      4611\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.72      0.93      0.81       107\n",
      "    class 1       1.00      0.78      0.87       112\n",
      "    class 2       0.99      0.90      0.95      2401\n",
      "    class 3       0.96      0.99      0.98      7198\n",
      "\n",
      "avg / total       0.97      0.97      0.97      9818\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      1.00      1.00       144\n",
      "    class 1       1.00      0.04      0.08      3359\n",
      "    class 2       0.23      1.00      0.38       980\n",
      "\n",
      "avg / total       0.83      0.28      0.18      4483\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      1.00      1.00       182\n",
      "    class 1       1.00      1.00      1.00       139\n",
      "    class 2       0.94      0.97      0.96      2667\n",
      "    class 3       0.94      0.87      0.90      1204\n",
      "\n",
      "avg / total       0.95      0.95      0.95      4192\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Office\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Office\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Office\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.00      0.00      0.00       187\n",
      "    class 1       0.00      0.00      0.00       193\n",
      "    class 2       0.65      1.00      0.79      1159\n",
      "    class 3       0.79      0.70      0.74      2049\n",
      "\n",
      "avg / total       0.66      0.72      0.68      3588\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.46      1.00      0.63       155\n",
      "    class 1       1.00      1.00      1.00       198\n",
      "    class 2       1.00      1.00      1.00      2171\n",
      "    class 3       1.00      0.89      0.94      1729\n",
      "\n",
      "avg / total       0.98      0.96      0.96      4253\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      1.00      1.00       177\n",
      "    class 1       1.00      1.00      1.00       206\n",
      "    class 2       0.92      1.00      0.96      2769\n",
      "    class 3       1.00      0.92      0.96      2861\n",
      "\n",
      "avg / total       0.96      0.96      0.96      6013\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      1.00      1.00       155\n",
      "    class 1       0.45      0.75      0.56       154\n",
      "    class 2       0.97      1.00      0.98      2470\n",
      "    class 3       1.00      0.96      0.98      5017\n",
      "\n",
      "avg / total       0.98      0.97      0.97      7796\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      1.00      1.00       164\n",
      "    class 1       1.00      1.00      1.00       342\n",
      "    class 2       1.00      0.37      0.55      2782\n",
      "    class 3       0.72      1.00      0.84      4584\n",
      "\n",
      "avg / total       0.84      0.78      0.75      7872\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.98      1.00      0.99       148\n",
      "    class 1       1.00      1.00      1.00       178\n",
      "    class 2       0.79      0.92      0.85      2630\n",
      "    class 3       0.91      0.77      0.83      2810\n",
      "\n",
      "avg / total       0.86      0.85      0.85      5766\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      1.00      1.00       126\n",
      "    class 1       1.00      1.00      1.00       135\n",
      "    class 2       1.00      1.00      1.00       246\n",
      "    class 3       1.00      1.00      1.00      3903\n",
      "\n",
      "avg / total       1.00      1.00      1.00      4410\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 13):\n",
    "\n",
    "    \n",
    "    if i==0: \n",
    "        shuf_test_dataset = test1\n",
    "        shuf_train_dataset = train1\n",
    "    elif i==1:\n",
    "        shuf_test_dataset = test2\n",
    "        shuf_train_dataset = train2\n",
    "    elif i==2:\n",
    "        shuf_test_dataset = test3\n",
    "        shuf_train_dataset = train3\n",
    "    elif i==3:\n",
    "        shuf_test_dataset = test4\n",
    "        shuf_train_dataset = train4\n",
    "    elif i==4:\n",
    "        shuf_test_dataset = test5\n",
    "        shuf_train_dataset = train5  \n",
    "        \n",
    "    elif i==5: \n",
    "        shuf_test_dataset = test6\n",
    "        shuf_train_dataset = train6\n",
    "    elif i==6:\n",
    "        shuf_test_dataset = test7\n",
    "        shuf_train_dataset = train7\n",
    "    elif i==7:\n",
    "        shuf_test_dataset = test8\n",
    "        shuf_train_dataset = train8\n",
    "    elif i==8:\n",
    "        shuf_test_dataset = test9\n",
    "        shuf_train_dataset = train9\n",
    "    elif i==9:\n",
    "        shuf_test_dataset = test10\n",
    "        shuf_train_dataset = train10    \n",
    "    elif i==10:\n",
    "        shuf_test_dataset = test11\n",
    "        shuf_train_dataset = train11\n",
    "    elif i==11:\n",
    "        shuf_test_dataset = test12\n",
    "        shuf_train_dataset = train12\n",
    "    elif i==12:\n",
    "        shuf_test_dataset = test13\n",
    "        shuf_train_dataset = train13     \n",
    "     \n",
    "    \n",
    "    \n",
    "    shuf_train_dataset = [row for row in shuf_train_dataset if len(row)==length_features]\n",
    "    shuf_test_dataset = [row for row in shuf_test_dataset if len(row)==length_features]\n",
    "\n",
    "    \n",
    "    ### Split X and Y\n",
    "    X_train, X_test = [], []\n",
    "    Y_train, Y_test = [], []\n",
    "    temp1, temp2 = [], []\n",
    "\n",
    "    for idx, row in enumerate(shuf_train_dataset):\n",
    "        for j in range(1, end_point_for_feature_scaling+1): # csv file에서 feature가 있는 index (1~13)\n",
    "            temp1.append(shuf_train_dataset[idx][j])\n",
    "        X_train.append(temp1)\n",
    "        temp1 = [] # temp 0으로 초기화\n",
    "\n",
    "    for idx, row in enumerate(shuf_test_dataset):\n",
    "        for j in range(1, end_point_for_feature_scaling+1):\n",
    "            temp2.append(shuf_test_dataset[idx][j])\n",
    "        X_test.append(temp2)\n",
    "        temp2 = [] \n",
    "\n",
    "    for idx, row in enumerate(shuf_train_dataset): Y_train.append(shuf_train_dataset[idx][0])\n",
    "    for idx, row in enumerate(shuf_test_dataset): Y_test.append(shuf_test_dataset[idx][0])\n",
    "\n",
    "    ### Convert to numpy array with data-type\n",
    "    X_train = np.array(X_train, dtype='float32')\n",
    "    X_test = np.array(X_test, dtype='float32')\n",
    "    Y_train = np.array(Y_train, dtype='int64')\n",
    "    Y_test = np.array(Y_test, dtype='int64')\n",
    "\n",
    "    # for inner test\n",
    "    test_X = X_test\n",
    "    test_y = Y_test\n",
    "    \n",
    "    \n",
    "    clf2 = SVC()\n",
    "    clf2.fit(X_train, Y_train) \n",
    "    prediction_SVM = clf2.predict(test_X)\n",
    "    \n",
    "    target_names = ['class 0', 'class 1', 'class 2', 'class 3']\n",
    "    a = classification_report(test_y, prediction_SVM, target_names=target_names)\n",
    "    print(a)\n",
    "    \n",
    "    \n",
    "    p_micro_list.append(metrics.precision_score(test_y, prediction_SVM, average='micro'))\n",
    "    r_micro_list.append(metrics.recall_score(test_y, prediction_SVM, average='micro'))\n",
    "    f_micro_list.append(metrics.f1_score(test_y, prediction_SVM, average='micro')) \n",
    "     \n",
    "    p_macro_list.append(metrics.precision_score(test_y, prediction_SVM, average='macro'))\n",
    "    r_macro_list.append(metrics.recall_score(test_y, prediction_SVM, average='macro'))\n",
    "    f_macro_list.append(metrics.f1_score(test_y, prediction_SVM, average='macro'))\n",
    "    \n",
    "    print \"\\n\\n\\n\"\n",
    "    \n",
    "    c0p = a[72]+a[73]+a[74]+a[75]\n",
    "    c0r = a[82]+a[83]+a[84]+a[85]\n",
    "    c0f = a[92]+a[93]+a[94]+a[95]\n",
    "    c0s = a[101]+a[102]+a[103]+a[104]+a[105]\n",
    "\n",
    "    c1p = a[125]+a[126]+a[127]+a[128]\n",
    "    c1r = a[135]+a[136]+a[137]+a[138]\n",
    "    c1f = a[145]+a[146]+a[147]+a[148]\n",
    "    c1s = a[154]+a[155]+a[156]+a[157]+a[158]\n",
    "\n",
    "    c2p = a[178]+a[179]+a[180]+a[181]\n",
    "    c2r = a[188]+a[189]+a[190]+a[191]\n",
    "    c2f = a[198]+a[199]+a[200]+a[201]\n",
    "    c2s = a[207]+a[208]+a[209]+a[210]+a[211]\n",
    "\n",
    "    c3p = a[231]+a[232]+a[233]+a[234]\n",
    "    c3r = a[241]+a[242]+a[243]+a[244]\n",
    "    c3f = a[251]+a[252]+a[253]+a[254]\n",
    "    c3s = a[260]+a[261]+a[262]+a[263]+a[264]\n",
    "    \n",
    "    c0p_list.append(c0p)\n",
    "    c0r_list.append(c0r)\n",
    "    c0f_list.append(c0f)\n",
    "    c0s_list.append(c0s)\n",
    "\n",
    "    c1p_list.append(c1p)\n",
    "    c1r_list.append(c1r)\n",
    "    c1f_list.append(c1f)\n",
    "    c1s_list.append(c1s)\n",
    "\n",
    "    c2p_list.append(c2p)\n",
    "    c2r_list.append(c2r)\n",
    "    c2f_list.append(c2f)\n",
    "    c2s_list.append(c2s)\n",
    "\n",
    "    c3p_list.append(c3p)\n",
    "    c3r_list.append(c3r)\n",
    "    c3f_list.append(c3f)\n",
    "    c3s_list.append(c3s)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0: 83.3846153846 28.602147476 - 91.7692307692 26.5566270048 - 86.6153846154 27.10531728 - 15469.2307692 2176.22984341\n",
      "class 1: 88.0769230769 29.3217208501 - 80.3076923077 34.4771599209 - 80.3076923077 34.6152136748 - 43415.3846154 84633.4435274\n",
      "class 2: 86.0 20.8474311275 - 89.6153846154 20.2694862048 - 86.6153846154 19.4522629158 - 210892.307692 78373.6460959\n",
      "class 3: 90.3076923077 12.1109271409 - 83.6923076923 21.0982486163 - 86.6153846154 22.9694935324 - 284446.153846 180868.101603\n"
     ]
    }
   ],
   "source": [
    "mean_std_print(c0p_list,c0r_list,c0f_list,c0s_list, c1p_list,c1r_list,c1f_list,c1s_list, c2p_list,c2r_list,c2f_list,c2s_list, c3p_list,c3r_list,c3f_list,c3s_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# c0p_list = []\n",
    "# c0r_list = []\n",
    "# c0f_list = []\n",
    "# c0s_list = []\n",
    "\n",
    "# c1p_list = []\n",
    "# c1r_list = []\n",
    "# c1f_list = []\n",
    "# c1s_list = []\n",
    "\n",
    "# c2p_list = []\n",
    "# c2r_list = []\n",
    "# c2f_list = []\n",
    "# c2s_list = []\n",
    "\n",
    "# c3p_list = []\n",
    "# c3r_list = []\n",
    "# c3f_list = []\n",
    "# c3s_list = []\n",
    "\n",
    "\n",
    "# labeled_dataset = csv_data_load_from_multiple_folders(dataset_path, labeled_dataset, 0)\n",
    "# labeled_dataset = [row for row in labeled_dataset if len(row)==length_features]\n",
    "# labeled_dataset = shuffle(labeled_dataset)\n",
    "# # cross_val_0 = labeled_dataset[0:int(len(labeled_dataset)*0.1)]\n",
    "# # cross_val_1 = labeled_dataset[int(len(labeled_dataset)*0.1):int(len(labeled_dataset)*0.2)]\n",
    "# # cross_val_2 = labeled_dataset[int(len(labeled_dataset)*0.2):int(len(labeled_dataset)*0.3)]\n",
    "# # cross_val_3 = labeled_dataset[int(len(labeled_dataset)*0.3):int(len(labeled_dataset)*0.4)]\n",
    "# # cross_val_4 = labeled_dataset[int(len(labeled_dataset)*0.4):int(len(labeled_dataset)*0.5)]\n",
    "# # cross_val_5 = labeled_dataset[int(len(labeled_dataset)*0.5):int(len(labeled_dataset)*0.6)]\n",
    "# # cross_val_6 = labeled_dataset[int(len(labeled_dataset)*0.6):int(len(labeled_dataset)*0.7)]\n",
    "# # cross_val_7 = labeled_dataset[int(len(labeled_dataset)*0.7):int(len(labeled_dataset)*0.8)]\n",
    "# # cross_val_8 = labeled_dataset[int(len(labeled_dataset)*0.8):int(len(labeled_dataset)*0.9)]\n",
    "# # cross_val_9 = labeled_dataset[int(len(labeled_dataset)*0.9):int(len(labeled_dataset)*1.0)]\n",
    "# cross_val_0 = labeled_dataset[0:int(len(labeled_dataset)*0.2)]\n",
    "# cross_val_1 = labeled_dataset[int(len(labeled_dataset)*0.2):int(len(labeled_dataset)*0.4)]\n",
    "# cross_val_2 = labeled_dataset[int(len(labeled_dataset)*0.4):int(len(labeled_dataset)*0.6)]\n",
    "# cross_val_3 = labeled_dataset[int(len(labeled_dataset)*0.6):int(len(labeled_dataset)*0.8)]\n",
    "# cross_val_4 = labeled_dataset[int(len(labeled_dataset)*0.8):int(len(labeled_dataset)*1.0)]\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(0, 10):\n",
    "\n",
    "    \n",
    "# #     if i==0: \n",
    "# #         shuf_test_dataset = cross_val_0\n",
    "# #         shuf_train_dataset = cross_val_1+cross_val_2+cross_val_3+cross_val_4+cross_val_5+cross_val_6+cross_val_7+cross_val_8+cross_val_9\n",
    "# #     elif i==1:\n",
    "# #         shuf_test_dataset = cross_val_1\n",
    "# #         shuf_train_dataset = cross_val_0+cross_val_2+cross_val_3+cross_val_4+cross_val_5+cross_val_6+cross_val_7+cross_val_8+cross_val_9\n",
    "# #     elif i==2:\n",
    "# #         shuf_test_dataset = cross_val_2\n",
    "# #         shuf_train_dataset = cross_val_0+cross_val_1+cross_val_3+cross_val_4+cross_val_5+cross_val_6+cross_val_7+cross_val_8+cross_val_9\n",
    "# #     elif i==3:\n",
    "# #         shuf_test_dataset = cross_val_3\n",
    "# #         shuf_train_dataset = cross_val_0+cross_val_1+cross_val_2+cross_val_4+cross_val_5+cross_val_6+cross_val_7+cross_val_8+cross_val_9\n",
    "# #     elif i==4:\n",
    "# #         shuf_test_dataset = cross_val_4\n",
    "# #         shuf_train_dataset = cross_val_0+cross_val_1+cross_val_2+cross_val_3+cross_val_5+cross_val_6+cross_val_7+cross_val_8+cross_val_9\n",
    "# #     elif i==5:\n",
    "# #         shuf_test_dataset = cross_val_5\n",
    "# #         shuf_train_dataset = cross_val_0+cross_val_1+cross_val_2+cross_val_3+cross_val_4+cross_val_6+cross_val_7+cross_val_8+cross_val_9\n",
    "# #     elif i==6:\n",
    "# #         shuf_test_dataset = cross_val_6\n",
    "# #         shuf_train_dataset = cross_val_0+cross_val_1+cross_val_2+cross_val_3+cross_val_4+cross_val_5+cross_val_7+cross_val_8+cross_val_9\n",
    "# #     elif i==7:\n",
    "# #         shuf_test_dataset = cross_val_7\n",
    "# #         shuf_train_dataset = cross_val_0+cross_val_1+cross_val_2+cross_val_3+cross_val_4+cross_val_5+cross_val_6+cross_val_8+cross_val_9\n",
    "# #     elif i==8:\n",
    "# #         shuf_test_dataset = cross_val_8\n",
    "# #         shuf_train_dataset = cross_val_0+cross_val_1+cross_val_2+cross_val_3+cross_val_4+cross_val_5+cross_val_6+cross_val_7+cross_val_9\n",
    "# #     elif i==9:\n",
    "# #         shuf_test_dataset = cross_val_9\n",
    "# #         shuf_train_dataset = cross_val_0+cross_val_1+cross_val_2+cross_val_3+cross_val_4+cross_val_5+cross_val_6+cross_val_7+cross_val_8\n",
    "\n",
    "\n",
    "#     if i==0: \n",
    "#         shuf_test_dataset = cross_val_0\n",
    "#         shuf_train_dataset = cross_val_1+cross_val_2+cross_val_3+cross_val_4\n",
    "#     elif i==1:\n",
    "#         shuf_test_dataset = cross_val_1\n",
    "#         shuf_train_dataset = cross_val_0+cross_val_2+cross_val_3+cross_val_4\n",
    "#     elif i==2:\n",
    "#         shuf_test_dataset = cross_val_2\n",
    "#         shuf_train_dataset = cross_val_0+cross_val_1+cross_val_3+cross_val_4\n",
    "#     elif i==3:\n",
    "#         shuf_test_dataset = cross_val_3\n",
    "#         shuf_train_dataset = cross_val_0+cross_val_1+cross_val_2+cross_val_4\n",
    "#     elif i==4:\n",
    "#         shuf_test_dataset = cross_val_4\n",
    "#         shuf_train_dataset = cross_val_0+cross_val_1+cross_val_2+cross_val_3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "#     ### Split X and Y\n",
    "#     X_train, X_test = [], []\n",
    "#     Y_train, Y_test = [], []\n",
    "#     temp1, temp2 = [], []\n",
    "\n",
    "#     for idx, row in enumerate(shuf_train_dataset):\n",
    "#         for j in range(1, end_point_for_feature_scaling+1): # csv file에서 feature가 있는 index (1~13)\n",
    "#             temp1.append(shuf_train_dataset[idx][j])\n",
    "#         X_train.append(temp1)\n",
    "#         temp1 = [] # temp 0으로 초기화\n",
    "\n",
    "#     for idx, row in enumerate(shuf_test_dataset):\n",
    "#         for j in range(1, end_point_for_feature_scaling+1):\n",
    "#             temp2.append(shuf_test_dataset[idx][j])\n",
    "#         X_test.append(temp2)\n",
    "#         temp2 = [] \n",
    "\n",
    "#     for idx, row in enumerate(shuf_train_dataset): Y_train.append(shuf_train_dataset[idx][0])\n",
    "#     for idx, row in enumerate(shuf_test_dataset): Y_test.append(shuf_test_dataset[idx][0])\n",
    "\n",
    "#     ### Convert to numpy array with data-type\n",
    "#     X_train = np.array(X_train, dtype='float32')\n",
    "#     X_test = np.array(X_test, dtype='float32')\n",
    "#     Y_train = np.array(Y_train, dtype='int64')\n",
    "#     Y_test = np.array(Y_test, dtype='int64')\n",
    "\n",
    "#     # for inner test\n",
    "#     test_X = X_test\n",
    "#     test_y = Y_test\n",
    "    \n",
    "    \n",
    "#     clf2 = SVC()\n",
    "#     clf2.fit(X_train, Y_train) \n",
    "#     prediction_SVM = clf2.predict(test_X)\n",
    "    \n",
    "#     target_names = ['class 0', 'class 1', 'class 2', 'class 3']\n",
    "#     a = classification_report(test_y, prediction_SVM, target_names=target_names)\n",
    "#     print(a)\n",
    "#     print \"\\n\"\n",
    "    \n",
    "#     c0p = a[72]+a[73]+a[74]+a[75]\n",
    "#     c0r = a[82]+a[83]+a[84]+a[85]\n",
    "#     c0f = a[92]+a[93]+a[94]+a[95]\n",
    "#     c0s = a[101]+a[102]+a[103]+a[104]+a[105]\n",
    "\n",
    "#     c1p = a[125]+a[126]+a[127]+a[128]\n",
    "#     c1r = a[135]+a[136]+a[137]+a[138]\n",
    "#     c1f = a[145]+a[146]+a[147]+a[148]\n",
    "#     c1s = a[154]+a[155]+a[156]+a[157]+a[158]\n",
    "\n",
    "#     c2p = a[178]+a[179]+a[180]+a[181]\n",
    "#     c2r = a[188]+a[189]+a[190]+a[191]\n",
    "#     c2f = a[198]+a[199]+a[200]+a[201]\n",
    "#     c2s = a[207]+a[208]+a[209]+a[210]+a[211]\n",
    "\n",
    "#     c3p = a[231]+a[232]+a[233]+a[234]\n",
    "#     c3r = a[241]+a[242]+a[243]+a[244]\n",
    "#     c3f = a[251]+a[252]+a[253]+a[254]\n",
    "#     c3s = a[260]+a[261]+a[262]+a[263]+a[264]\n",
    "    \n",
    "#     c0p_list.append(c0p)\n",
    "#     c0r_list.append(c0r)\n",
    "#     c0f_list.append(c0f)\n",
    "#     c0s_list.append(c0s)\n",
    "\n",
    "#     c1p_list.append(c1p)\n",
    "#     c1r_list.append(c1r)\n",
    "#     c1f_list.append(c1f)\n",
    "#     c1s_list.append(c1s)\n",
    "\n",
    "#     c2p_list.append(c2p)\n",
    "#     c2r_list.append(c2r)\n",
    "#     c2f_list.append(c2f)\n",
    "#     c2s_list.append(c2s)\n",
    "\n",
    "#     c3p_list.append(c3p)\n",
    "#     c3r_list.append(c3r)\n",
    "#     c3f_list.append(c3f)\n",
    "#     c3s_list.append(c3s)\n",
    "    \n",
    "#     labeled_dataset = []"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
